<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>While My MCMC Gently Samples - Thomas Wiecki</title><link>http://twiecki.github.com/</link><description>Bayesian modeling, Computational Psychiatry, and Python</description><lastBuildDate>Wed, 05 Jul 2017 10:00:00 -0400</lastBuildDate><item><title>What's new in PyMC3 3.1</title><link>http://twiecki.github.com/blog/2017/07/05/new-in-pymc3-31/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;We recently released &lt;a href="https://github.com/pymc-devs/pymc3/blob/master/RELEASE-NOTES.md#pymc3-31-june-23-2017"&gt;PyMC3 3.1&lt;/a&gt; after the first stable 3.0 release in January 2017. You can update either via &lt;code&gt;pip install pymc3&lt;/code&gt; or via &lt;code&gt;conda install -c conda-forge pymc3&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;A lot is happening in PyMC3-land. One thing I am particularily proud of is the developer community we have …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Wed, 05 Jul 2017 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2017-07-05:/blog/2017/07/05/new-in-pymc3-31/</guid><category>bayesian</category><category>statistics</category><category>pymc3</category></item><item><title>Random-Walk Bayesian Deep Networks: Dealing with Non-Stationary Data</title><link>http://twiecki.github.com/blog/2017/03/14/random-walk-deep-net/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Download the NB: &lt;a href="https://github.com/twiecki/WhileMyMCMCGentlySamples/blob/master/content/downloads/notebooks/random_walk_deep_net.ipynb"&gt;https://github.com/twiecki/WhileMyMCMCGentlySamples/blob/master/content/downloads/notebooks/random_walk_deep_net.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;(c) 2017 by &lt;a href="https://twitter/twiecki"&gt;Thomas Wiecki&lt;/a&gt; -- &lt;a href="https://quantopian.com"&gt;Quantopian Inc.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Most problems solved by Deep Learning are stationary. A cat is always a cat. The rules of Go have remained stable for 2,500 years, and will likely …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 14 Mar 2017 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2017-03-14:/blog/2017/03/14/random-walk-deep-net/</guid><category>bayesian statistics deep learning</category></item><item><title>Why hierarchical models are awesome, tricky, and Bayesian</title><link>http://twiecki.github.com/blog/2017/02/08/bayesian-hierchical-non-centered/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2017 by Thomas Wiecki&lt;/p&gt;
&lt;p&gt;Hierarchical models are underappreciated. Hierarchies exist in many data sets and modeling them appropriately adds a boat load of statistical power (the common metric of statistical power). I provided an introduction to hierarchical models in a &lt;a href="http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/"&gt;previous blog post: Best Of Both Worlds: Hierarchical Linear …&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Wed, 08 Feb 2017 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2017-02-08:/blog/2017/02/08/bayesian-hierchical-non-centered/</guid><category>bayesian statistics hierarchical</category></item><item><title>Bayesian Deep Learning Part II: Bridging PyMC3 and Lasagne to build a Hierarchical Neural Network</title><link>http://twiecki.github.com/blog/2016/07/05/bayesian-deep-learning/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;(c) 2016 by Thomas Wiecki&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Recently, I blogged about &lt;a href="http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/"&gt;Bayesian Deep Learning with PyMC3&lt;/a&gt; where I built a simple hand-coded Bayesian Neural Network and fit it on a toy data set. Today, we will build a more interesting model using &lt;a href="https://lasagne.readthedocs.io/en/latest/"&gt;Lasagne&lt;/a&gt;, a flexible &lt;code&gt;Theano&lt;/code&gt; library for constructing various types of …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 05 Jul 2016 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2016-07-05:/blog/2016/07/05/bayesian-deep-learning/</guid><category>bayesian statistics deep learning neural networks</category></item><item><title>Bayesian Deep Learning</title><link>http://twiecki.github.com/blog/2016/06/01/bayesian-deep-learning/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="Variational-Inference:-Bayesian-Neural-Networks"&gt;Variational Inference: Bayesian Neural Networks&lt;a class="anchor-link" href="#Variational-Inference:-Bayesian-Neural-Networks"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;&lt;p&gt;(c) 2016-2018 by Thomas Wiecki, updated by Maxim Kochurov&lt;/p&gt;
&lt;p&gt;Original blog post: &lt;a href="http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/"&gt;http://twiecki.github.io/blog/2016/06/01/bayesian-deep-learning/&lt;/a&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h2 id="Current-trends-in-Machine-Learning"&gt;Current trends in Machine Learning&lt;a class="anchor-link" href="#Current-trends-in-Machine-Learning"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;There are currently three big trends in machine learning: &lt;strong&gt;Probabilistic Programming&lt;/strong&gt;, &lt;strong&gt;Deep Learning&lt;/strong&gt; and "&lt;strong&gt;Big Data&lt;/strong&gt;". Inside of PP …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Wed, 01 Jun 2016 10:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2016-06-01:/blog/2016/06/01/bayesian-deep-learning/</guid><category>bayesian statistics deep learning neural networks</category></item><item><title>MCMC sampling for dummies</title><link>http://twiecki.github.com/blog/2015/11/10/mcmc-sampling/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;When I give talks about probabilistic programming and Bayesian statistics, I usually gloss over the details of how inference is actually performed, treating it as a black box essentially. The beauty of probabilistic programming is that you actually don't &lt;em&gt;have&lt;/em&gt; to understand how the inference works in order to build …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 10 Nov 2015 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2015-11-10:/blog/2015/11/10/mcmc-sampling/</guid><category>bayesian statistics</category></item><item><title>A modern guide to getting started with Data Science and Python</title><link>http://twiecki.github.com/blog/2014/11/18/python-for-data-science/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Python has an extremely rich and healthy ecosystem of data science tools. Unfortunately, to outsiders this ecosystem can look like a jungle (cue snake joke). In this blog post I will provide a step-by-step guide to venturing into this PyData jungle.&lt;/p&gt;
&lt;p&gt;What's wrong with the many lists of PyData packages …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 18 Nov 2014 10:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2014-11-18:/blog/2014/11/18/python-for-data-science/</guid><category>intro datascience</category></item><item><title>The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3</title><link>http://twiecki.github.com/blog/2014/03/17/bayesian-glms-3/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;h1 id="The-best-of-both-worlds:-Hierarchical-Linear-Regression-in-PyMC3"&gt;The best of both worlds: Hierarchical Linear Regression in PyMC3&lt;a class="anchor-link" href="#The-best-of-both-worlds:-Hierarchical-Linear-Regression-in-PyMC3"&gt;&amp;#182;&lt;/a&gt;&lt;/h1&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Today's blog post is co-written by my student &lt;a href="http://www.linkedin.com/pub/danne-elbers/69/3a2/7ba"&gt;Danne Elbers&lt;/a&gt; who is doing her masters thesis with me on computational psychiatry using Bayesian methods. This post also borrows heavily from a &lt;a href="http://nbviewer.ipython.org/github/fonnesbeck/multilevel_modeling/blob/master/multilevel_modeling.ipynb?create=1"&gt;Notebook&lt;/a&gt; by &lt;a href="http://biostat.mc.vanderbilt.edu/wiki/Main/ChrisFonnesbeck"&gt;Chris Fonnesbeck&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The power of Bayesian modelling …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 17 Mar 2014 09:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2014-03-17:/blog/2014/03/17/bayesian-glms-3/</guid><category>bayesian statistics</category></item><item><title>Easily distributing a parallel IPython Notebook on a cluster</title><link>http://twiecki.github.com/blog/2014/02/24/ipython-nb-cluster/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Have you ever asked yourself: "Do I want to spend 2 days adjusting this analysis to run on the cluster and wait 2 days for the jobs to finish or do I just run it locally with no extra work and just wait a week."&lt;/p&gt;
&lt;p&gt;If so, this blog post …&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 24 Feb 2014 09:00:00 -0500</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2014-02-24:/blog/2014/02/24/ipython-nb-cluster/</guid><category>computation</category></item><item><title>Hammer time: Nailing the emcee ensemble sampler onto PyMC</title><link>http://twiecki.github.com/blog/2013/09/23/emcee-pymc/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;tl;dr: I hacked the &lt;a href="http://dan.iel.fm/emcee/"&gt;&lt;code&gt;emcee&lt;/code&gt;--The MCMC-Hammer&lt;/a&gt; ensemble sampler to work on &lt;code&gt;PyMC&lt;/code&gt; models.&lt;/p&gt;
&lt;h2 id="Motivation"&gt;Motivation&lt;a class="anchor-link" href="#Motivation"&gt;&amp;#182;&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://pymc-devs.github.io/pymc/"&gt;&lt;code&gt;PyMC&lt;/code&gt;&lt;/a&gt; is an awesome Python module to perform Bayesian inference. It allows for flexible model creation and has basic MCMC samplers like &lt;a href="http://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm"&gt;Metropolis-Hastings&lt;/a&gt;. The upcoming PyMC3 will feature much fancier samplers like &lt;a href="http://en.wikipedia.org/wiki/Hybrid_Monte_Carlo"&gt;Hamiltonian-Monte Carlo …&lt;/a&gt;&lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 23 Sep 2013 09:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2013-09-23:/blog/2013/09/23/emcee-pymc/</guid><category>bayesian statistics</category></item><item><title>This world is far from Normal(ly distributed): Bayesian Robust Regression in PyMC3</title><link>http://twiecki.github.com/blog/2013/08/27/bayesian-glms-2/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Author: Thomas Wiecki&lt;/p&gt;
&lt;p&gt;This tutorial first appeard as a post in small series on Bayesian GLMs on my blog:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://twiecki.github.com/blog/2013/08/12/bayesian-glms-1/"&gt;The Inference Button: Bayesian GLMs made easy with PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/"&gt;This world is far from Normal(ly distributed): Robust Regression in PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/"&gt;The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3 …&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Tue, 27 Aug 2013 12:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2013-08-27:/blog/2013/08/27/bayesian-glms-2/</guid><category>bayesian statistics</category></item><item><title>The Inference Button: Bayesian GLMs made easy with PyMC3</title><link>http://twiecki.github.com/blog/2013/08/12/bayesian-glms-1/</link><description>&lt;p&gt;
&lt;div class="cell border-box-sizing text_cell rendered"&gt;&lt;div class="prompt input_prompt"&gt;
&lt;/div&gt;
&lt;div class="inner_cell"&gt;
&lt;div class="text_cell_render border-box-sizing rendered_html"&gt;
&lt;p&gt;Author: Thomas Wiecki&lt;/p&gt;
&lt;p&gt;This tutorial appeared as a post in a small series on Bayesian GLMs on my blog:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://twiecki.github.com/blog/2013/08/12/bayesian-glms-1/"&gt;The Inference Button: Bayesian GLMs made easy with PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://twiecki.github.io/blog/2013/08/27/bayesian-glms-2/"&gt;This world is far from Normal(ly distributed): Robust Regression in PyMC3&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/"&gt;The Best Of Both Worlds: Hierarchical Linear Regression in PyMC3 …&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Thomas Wiecki</dc:creator><pubDate>Mon, 12 Aug 2013 07:00:00 -0400</pubDate><guid isPermaLink="false">tag:twiecki.github.com,2013-08-12:/blog/2013/08/12/bayesian-glms-1/</guid><category>bayesian statistics</category></item></channel></rss>